---
title: "Distributions: Discrete and Continuous"
author: "Maureen Zajic 116487351 Abdulrahman Azizi 118448039"
output:
  html_document:
    number_sections: yes    
    toc: yes
  pdf_document:
    toc: yes
---
# Visualizing Discrete Distributions
In this problem we will draw plots for some of the discrete probability distributions that we have studied in class

## Binomial distribution.
We will plot the density function for the binomial distribution Bin(n, p).

Note: 

1) The values for this random variable are 0, 1, 2, ..., n.

2) The density plot will have a bar of height P(X=k), at the point 'k' on the x-axis. 

3) In the plot include a vertical line at the expected value of Bin(n,p). 

Write a function plot_binom, that takes input values: n and p, and returns the density plot of Bin(n,p). 


```{r}
plot_binom <- function(n,p){
  x <- 0:n
  bin <- dbinom(x, size = n, prob = p)
  mu_X <- n*p #mean of binomial distribution
  plot(x, bin, type = "h", lwd = 5,
       main = paste("Binomial Mass Function", "n = ", n, "p = ",  p),
       xlab = "x", ylab = "P(X=x)")
  abline(v = mu_X, col = 'red', lwd = 4)
}
```
Fix n = 40. Compute plots for the following values of p: 0.05, 0.1, 0.4, 0.6, 0.9, 0.95. 

Use the command "par(mfrow=c(3,2))" to have all the plots on the same frame.

```{r}
par(mfrow=c(3,2))
plot_binom(40, 0.05)
plot_binom(40, 0.1)
plot_binom(40, 0.4)
plot_binom(40, 0.6)
plot_binom(40, 0.9)
plot_binom(40, 0.95)
```

Write at least two observations that you can note from these plots. Consider skewness and symmetry.

Answer:

  1. The closer p is to 0.5, the more symmetrical the plot will be.
  
  2. Low p = skewed right, high p = skewed left

## Poisson Distribution.
We will plot the density function for the Poison distribution Pois(mu).

Note: 

1) The values for this random variable are: 0, 1, 2, 3, .... 

2) The density plot will have a bar of height P(X=k), at the point 'k' on the x-axis.

3) Since most of the densities will be concentrated at lower values of k, we will fix a large enough value of n, say n = 100, when drawing the density plots. 

4) In the plot include a vertical line at the expected value of Pois(mu). 

Write a function plot_pois, that takes input values: mu, and returns the density plot of Pois(mu).

```{r}
n <- 70 
plot_pois <- function(mu){
  x <- 0:n
  pois <- dpois(x, lambda = mu)
  mu_X <- mu
  plot(x, pois, type = "h", lwd = 5,
       main = paste("Poisson density: mu = ", mu),
       xlab = "x", ylab = "P(X=x)")
  abline(v = mu_X, col = 'red', lwd = 4)
}
```

For the following values of mu compute the plots for the Poisson Density:

mu: 0.5, 1, 5, 8, 20, 50

```{r}
par(mfrow=c(3,2))
plot_pois(.5)
plot_pois(1)
plot_pois(5)
plot_pois(8)
plot_pois(20)
plot_pois(50)
```

What observations can you make about the density plots of the Poisson distribution for large values of mu?

Answer:

  1. The larger the value of mu, the more skewed left the plot becomes.
  
  2. The smaller the value of mu, the more skewed right the plot becomes.
  
  3. The larger the value of mu, the denser the plot becomes (more, smaller humps)

Now use your plot functions to evaluate the following two plots on the same frame (one below the other):

plot_binom(100, 0.05)

plot_pois(5)

```{r}
par(mfrow = c(2,1))
plot_binom(100, 0.05)
plot_pois(5)
```

What observations can you make?

Answer: These are the same plot, because the mean for the binomial mass function is n * p = 100 * .05 = 5 which is the mu for the poisson density function

# Normal Distibution
In this section we will explore the normal distribution. 

## Fixed mean, varying standard deviation
### Plotting Densities
Set $\mu = 5$. For values of $\sigma$ given by $0.2, 0.4, 0.8, 1, 1.3, 1.8, 2$, plot the densities of $N(\mu, \sigma)$ in the same plot. It might help if (1) you have the densities of $N(\mu = 5, \sigma = 0.2)$ and $N(\mu = 5, \sigma = 2)$ to be blue in color and the rest to be red. (2) choose appropriate limits for the x-axis (use x_lim parameter in the plot funtion) and y-axis (use y_lim). 

```{r}
sd <- c(0.2, 0.4, 0.8, 1, 1.3, 1.8, 2)
mu <- 5
for(sigma in sd){
  x <- mu + seq(-3, 3, length.out = 1000)*sigma
  y <- dnorm(x, mean = mu, sd = sigma)
  
  if (sigma == .2){
    plot(x, y,
         type = "l",
         col = "blue",
         xlim = c(-2.5, 12.5),
         ylim = c(0, 2),
         xlab="x", ylab="f(x)"
         )
  } else {
    if(sigma == 2){
      lines(x, y, col = "blue")
    } else {
      lines(x, y, col = "red")
    }
  }
}
abline(v = 5, col = "black")
```
What do you notice about the plot? Comment about how the width changes.

Answer: As the sigma value gets larger, not only does the range of the plot get larger, but the value of f(x) gets smaller

### Plotting Cummulative Distribution Functions
Set $\mu = 5$. For values of $\sigma$ given by $0.2, 0.4, 0.8, 1, 1.3, 1.8, 2$, plot the cummulative distribution function of $N(\mu, \sigma)$ in the same plot.
It might help if (1) you have the cdf of $N(\mu = 5, \sigma = 0.2)$ and $N(\mu = 5, \sigma = 2)$ to be blue in color and the rest to be red. (2) choose appropriate limits for the x-axis (use x_lim parameter in the plot funtion) and y-axis (use y_lim).
```{r}
for(sigma in sd){
  x <- x <- seq(-7, 17, length.out = 10000)
  y <- pnorm(x, mean = mu, sd = sigma)
  
  if (sigma == .2){
    plot(x, y,
         type = "l",
         col = "blue",
         xlim = c(-1, 12),
         ylim = c(0, 1),
         xlab="x", ylab="F_X(x)"
         )
  } else {
    if(sigma == 2){
      lines(x, y, col = "blue")
    } else {
      lines(x, y, col = "red")
    }
  }
}
```
What information does the point of intersection of two cdfs give us?

Answer: The expected value is 5

## Varying mean, fixed standard deviation
### Plotting Densities 
Set $\sigma = 0.4$. For values of $\mu$ given by $-1, -0.5, 0, 0.4, 0.9, 2.5, 4$ plot the densities of $N(\mu, \sigma)$ in the same plot. You might need to choose appropriate limits for the x-axis.
```{r}
x <- seq(-2.5, 5.5, length.out = 1000)
mus <- c(-1, -0.5, 0, 0.4, 0.9, 2.5, 4)
sigma = .4

for(mu in mus){
  x <- mu + seq(-3, 3, length.out = 1000)*sigma
  y <- dnorm(x, mean = mu, sd = sigma)
  
  if (mu == -1){
    plot(x, y,
         type = "l",
         col = "red",
         xlim = c(-2.5, 6),
         ylim = c(0, 1),
         xlab="x", ylab="f(x)"
         )
  } else {
    lines(x, y, col = "red")
  }
}
```

### Plotting Cummulative Distribution Functions
Set $\sigma = 0.4$. For values of $\mu$ given by $-1, -0.5, 0, 0.4, 0.9, 2.5, 4$ plot the cummulative distribution functions of $N(\mu, \sigma)$ in the same plot. You might need to choose appropriate limits for the x-axis.
```{r}
for(mu in mus){
  x <- seq(-7, 17, length.out = 10000)
  y <- pnorm(x, mean = mu, sd = sigma)
  
  if (mu == -1){
    plot(x, y,
         type = "l",
         col = "red",
         xlim = c(-3, 6),
         ylim = c(0, 1),
         xlab="x", ylab="F_X(x)"
         )
  } else {
    lines(x, y, col = "red")
  }
}
```


# Gamma Distribution
We will plot the Gamma distibution for different shapes and scales. You might need to adjust the limits of x and y axes appropriately.

## $\alpha =1$ , varying scales
Set $\alpha = 1$, vary $\beta$ over $0.2, 0.6, 1, 1.5, 2$. Plot the densities of $\text{Gamma}(\alpha, \beta)$ in a single plot.

```{r}

beta <- c(2,.2, 0.6, 1, 1.5)


  for (b in beta){
alpha = 1
x <- seq(0, 7, length.out = 5000)

  y <- dgamma(x,alpha,b)
  if(b == 2){
  plot(x,y,type = "l",main = paste("Gamma distribution", "alpha = ", alpha, "beta = 0.2, 0.6, 1, 1.5, 2"),col = "red")
  }else{
    
    lines(x,y)
  }


}

  

```

## $\alpha =0.6$ , varying scales
Set $\alpha = 0.6$, vary $\beta$ over $0.2, 0.6, 1, 1.5, 2$. Plot the densities of $\text{Gamma}(\alpha, \beta)$ in a single plot.

```{r}

beta <- c(2,.2, 0.6, 1, 1.5)


  for (b in beta){
alpha = .6
x <- seq(0, 1, length.out = 500)

  y <- dgamma(x,alpha,b)
  if(b == 2){
  plot(x,y,type = "l",main = paste("Gamma distribution", "alpha = ", alpha, "beta = 0.2, 0.6, 1, 1.5, 2"),col = "blue")
  }else{
    lines(x,y)
  }
  
    
}


```

## $\alpha = 2$ , varying scales
Set $\alpha = 2$, vary $\beta$ over $0.2, 0.6, 1, 1.5, 2$. Plot the densities of $\text{Gamma}(\alpha, \beta)$ in a single plot.
```{r}

beta <- c(2,.2, 0.6, 1, 1.5)


  for (b in beta){
alpha = 2
x <- seq(0, 10, length.out = 2000)
 y <- dgamma(x,alpha,b)
if(b == 2){
  plot(x,y,type = "l",main = paste("Gamma distribution", "alpha = ", alpha, "beta = 0.2, 0.6, 1, 1.5, 2"), col = "green")
} else{
  lines(x,y)
}

}


```

## $\alpha = 5$ , varying scales
Set $\alpha = 5$, vary $\beta$ over $0.2, 0.6, 1, 1.5, 2$. Plot the densities of $\text{Gamma}(\alpha, \beta)$ in a single plot.
```{r}

beta <- c(2,.2, 0.6, 1, 1.5)


  for (b in beta){
alpha = 5
x <- seq(0, 30, length.out = 2000)

  y <- dgamma(x,alpha,b)
  if(b == 2){
  plot(x,y,type = "l",main = paste("Gamma distribution", "alpha = ", alpha, "beta = 0.2, 0.6, 1, 1.5, 2"),col = "blue")
  } else{
    
    lines(x,y)
  }

}



```

# Bayes's Theorem and Witnesses
Recall the hit-and-run example from the asynchronous lecture and HW4. We noted that the Bayes' probabilities are calculated as the following formula 
$$ P(B|W) = \frac{pq}{pq + (1-p)(1-q)},$$
where $P(B) = q$ and $P(W|B) = p$ (check notes). 
We also noted in HW4 that if $P(W|B)=p > \frac{1}{2}$ we will have
$$ P(B|W) > P(B).$$

In this problem, we will explore how changing the level of Witness-Reliability, that is $p$, will affect the chance of getting a Blue Cab driver arrested. 

Recall that $P(B)$ is the probability that the Blue cab is at fault with no added information. We will now run multiple iteration of Bayes' rule, and at every iteration, we will update the value of $P(B)$ with the value of $P(B|W)$ from earlier iteration. From our experience from the homework, if $p > \frac{1}{2}$, we must have $P(B) \longrightarrow 1$ as the number of iterations increase (intuitively, the probability that the Blue cab is at fault will go to 1 as the number of "reliable witness" who say that "the Blue Cab is at fault" increases). 

Write a function called "bayes" that takes input $q, p$ and outputs $P(B|W)$ (use the formula above)
```{r}
bayes <- function(p, q){
  return(p*q/(p*q+(1-p)*(1-q)))
}

```

## Reliable Witnesses with fixed probability
In this part, we will assume that we are using testimony of reliable witnesses with fixed reliability $p$. 

### Initial Plots
Initialize $p=0.6$, $q=0.01$, and q_vals = c(), the empty vector. Run a for loop (1 in 1:40) inside it, update q at every iteration to $q = \text{bayes}(p,q)$, and concatenate the vector q_vals with this new value of q. 
```{r}
p <- 0.6
q <- 0.01
q_vals <- c()
for(i in 1:40){
  q <- bayes(p, q)
  q_vals <- c(q_vals, q)
}


```

Construct a plot with x-axis 1:40 and y-axis q_vals.
```{r}

x<- 1:40
y <- q_vals
plot(x,y)
lines(x, q_vals, col = "blue")




```

Repeat the above experiment with $p=0.4$, $q=0.99$. 
```{r}

p <- 0.4
q <- 0.99
q_vals2 <- c()
for(i in 1:40){
  q <- bayes(p, q)
  q_vals2 <- c(q_vals2, q)
}


x<- 1:40
y <- q_vals2
plot(x,y)
lines(x, q_vals2, col = "green")




```


### How many reliable Witnesses needed?
Suppose the police decide to arrest the Blue cab driver if $P(B|W) \ge 0.9$. 

Suppose we intialize  $p=0.6$ (witness reliability), $q=0.01$ (proportion of Blue cabs in the city), how many witnesses with reliability level $p$ would we need for the police to consider arresting the Blue cab? 

Ans: You need 17 witnesses with reliability level p to consider arresting the blue
cab.

You will need a counter variable initialized to zero and a while loop inside which you update $q$ using the bayes function, and update the counter by 1 at every iteration of the while loop. 
```{r}

acceptable_threshold <- 0.9 
p <- 0.6
q <- 0.01
counter <- 0

while(q < acceptable_threshold){
  
  q<- bayes(p,q)
  counter <- counter + 1
  
}

counter #displays amount needed
```


## Working with two types of witnesses
In this problem we will work with two types of witnesses (1) reliable witnesses with fixed reliability level $p_1 > \frac{1}{2}$ and (2) unreliable witness with fixed reliability level $p_2 < \frac{1}{2}$. 

### Initial Plots
Initialize $p_1=0.6$, $p_2 = 0.45$, $q=0.01$, and q_vals = c(), the empty vector. Run a for loop (1 in 1:90) inside it, update q at every even iteration to $q = \text{bayes}(p_2,q)$, and at every odd iteration to $q = \text{bayes}(p_1,q)$ (You will need to use a "if" command), and finally concatanating the vector q_vals with the new value of q at every iteration. 
```{r}
p_1 <- .6
p_2 <- .45
q <- .01
q_vals3 <- c()

for(i in 1:90){
  
  if(i%%2 == 0){
    q<-bayes(p_2,q)
  }else{
    q<-bayes(p_1,q)
    
  }
 q_vals3 <- c(q_vals3,q) 
}




```

Construct a plot with x-axis 1:90 and y-axis q_vals.
```{r}


x <- 1:90
y <- q_vals3


plot(x,y, xlab = "number of witnesses", ylab = "probability value")
lines(x,y, type = "l", col = "red")




```
What do you notice? (Compared to case with single witness)

Ans: the probability value of q increases at a slower rate and also bounces up and down as each new witness pulls the value of q to be greater than or less than 1/2.

### How many witnesses needed?
Suppose the police decide to arrest the Blue cab driver if $P(B|W) \ge 0.9$. 

Initialize $p_1=0.6$, $p_2 = 0.45$, $q=0.01$. How many witnesses will we have to have if we are going to sequentially work with one reliable witness followed by an unreliable witness? 

Ans: we need 65 witnesses

```{r}

p_1 <- .6
p_2 <- .45
q <- .01
counter = 0

while(q<.9){
  
  if(counter%%2 == 0){
    q<-bayes(p_1,q)
  }else{
    q<-bayes(p_2,q)
    
  }
  counter = counter+1
  }


counter






```

This problem can be generalized to choosing $p$ from any given probability distribution on $(0,1)$, we will be working with the Beta distribution later in the semester, which can be an interesting candidate to sample our values for $p$ (that is witness reliability).  

## Working with four types of witnesses
In this problem we will work with two types of witnesses (1) two reliable witnesses with fixed reliability level $p_1, p_2 > \frac{1}{2}$ and (2) two unreliable witnesses with fixed reliability level $p_3, p_4 < \frac{1}{2}$. 

### Initial Plots
Initialize $q=0.01$ and we will sample $p$ from the vector c(0.6, 0.8, 0.45, 0.3) and suppose choosing a witness with either of these witness-reliabilities is equally likely.

Now let q_vals = c(), the empty vector and run a for loop (1 in 1:100) inside it, update q by sampling p from the vector c(0.6, 0.8, 0.45, 0.3), and concatanating the vector q_vals with the new value of q at every iteration. 
```{r}



q <- .01
p <- c(0.6,0.8,0.45,0.3)
q_vals4 <- c()

for(i in 1:100){
  probValue <- sample(p, size = 1, replace = TRUE)
  q <- bayes(probValue,q)
  
  q_vals4 <- c(q_vals4,q)
    }











```

Construct a plot with x-axis 1:100 and y-axis q_vals.
```{r}


x <- 1:100
y <- q_vals4


plot(x,y, xlab = "number of witnesses", ylab = "probability value")
lines(x,y, type = "l", col = "red")




```
What do you notice? How does this compare with the earlier cases?

Ans: This case is much more random in terms of the results, although most scenarios approach a probability close to 1, it is possible for the probability of q to also approach .001 instead.

### How many witnesses needed?
Suppose the police decide to arrest the Blue cab driver if $P(B|W) \ge 0.9$. 

Initialize $q=0.01$ and we will sample $p$ from the vector c(0.6, 0.8, 0.45, 0.3) and suppose choosing a witness with either of these witness-reliabilities is equally likely. How many witnesses will we need to have if we are going to uniformly sample from each of these four types of of witnesses at every step? 

Ans: The answer is unknown, as the results change with every experiment. However, by repeating the experiment numerous times, we can find an empyrical probability.
The empyrical probability we get over time is around 39

```{r}

Bayes4 <- function(){
q <- .01
p <- c(0.6,0.8,0.45,0.3)
counter = 0

while(q<.9){
  probValue <- sample(p, size = 1, replace = TRUE)
  q <- bayes(probValue,q)
  
  counter = counter+1
    }



return(counter)
}


Bayes4Result <- 0
for(i in 1:5000){
  Bayes4Result = Bayes4Result + Bayes4()
}

Bayes4Result = Bayes4Result/5000

print(Bayes4Result)





```

## BONUS: Working with witnesses coming from a Beta distribution
In this problem we will assume that the witness reliability of the people in the city follows the Beta distribution with parameters $\alpha$, $\beta$. Choose $\alpha, \beta$ in such a way that the expected value of this Beta distribution is greater than .65. 

### Initial Plots
Initialize $q=0.01$ and we will choose $p$ by sampling the Beta distribution with parameters $\alpha, \beta$ chosen above.

Now let q_vals = c(), the empty vector and run a for loop (1 in 1:100) inside it, update q by sampling p $\text{Beta}(\alpha, \beta)$, and concatanating the vector q_vals with the new value of q at every iteration. 
```{r}
a <- 2.1
b <- 1

q <- .01

q_vals5 = c()

for(i in 1:100){
  p_0 <- rbeta(1, shape1 = a, shape2 = b)
  q <- bayes(p_0,q)
  
  q_vals5 <- c(q_vals5, q)
    }







```

Construct a plot with x-axis 1:100 and y-axis q_vals.
```{r}


x <- 1:100
y <- q_vals5


plot(x,y, xlab = "number of witnesses", ylab = "probability value")
lines(x,y, type = "l", col = "red")




```
What do you notice? How does this compare with the earlier cases?

Ans: This scenario is also randomly calculated, but because the expected value is > 1/2 we are approaching a witness reliability value of 1.

### How many witnesses needed?
Suppose the police decide to arrest the Blue cab driver if $P(B|W) \ge 0.9$. 

Initialize $q=0.01$ and we will choose $p$ by sampling the Beta distribution with parameters $\alpha, \beta$ chosen above. How many witnesses will we need to have in this setting? 

7.59 witnesses needed when alpha = 2.1 and beta = 1.25

```{r}
ExperimentBayes <- function(){
a <- 2.1
b <- 1

q <- .01

counter = 0

while(q < .9){
  
  p_1 <- rbeta(1, shape1 = a, shape2 = b)
  q <- bayes(p_1,q)
  

  counter = counter+1
    }

return(counter)
}



sum = 0
for (i in 1:20000){
  
  sum = sum + ExperimentBayes()
  
}
sum = sum/20000
print(sum)





#our answer is on average 23 witnesses needed for alpha = 2.1, beta = 1



```



